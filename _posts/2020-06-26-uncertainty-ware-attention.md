---  
layout: post  
title:  "Uncertainty-Aware Attention"  
date:   2020-06-26
excerpt: ""  
tag:  
- Deep Learning
- Bayesian Neural Network

comments: false  
---  

# Uncertainty-Aware Attention

Attentionì€ ì»´í“¨í„°ë¹„ì „, ìì—°ì–´ì²˜ë¦¬ Taskë“¤ì˜ ë¬¸ì œë¥¼ í‘¸ëŠ”ë° ëŒ€ë‹¨íˆ ì„±ê³µì ì´ë‹¤.

Inputì— ëŒ€í•´ì„œ Attention-valueë¥¼ êµ¬í•¨ìœ¼ë¡œì¨ Inputì— ëŒ€í•´ì„œ ì–´ë–¤ ê²ƒì— ëŒ€í•´ ë” Attendí•  ì§€ êµ¬í•¨ìœ¼ë¡œì¨ 
Input-Adaptiveí•œ ë°©ì‹ìœ¼ë¡œ featuresì— ëŒ€í•´ì„œ ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•  ìˆ˜ ìˆìœ¼ë©°, ìœ„ ë°©ì‹ìœ¼ë¡œ êµ¬í•œ ëª¨ë¸ì€ ëŒ€ê°œ ë†’ì€ Accuracyë¥¼ ê°€ì§€ë©°, Interpretableí•˜ë‹¤.

ê·¸ëŸ¬ë‚˜ ë§ì€ ë¬¸ì œì—ì„œ Accuracy ë³´ë‹¤ precision í˜¹ì€ Recallì´ ì¤‘ìš”í•œ metricì¼ ê²½ìš°ê°€ ë§ì€ë° ê·¸ ì¤‘ healthcareì—ì„  Recallì´ ì¤‘ìš”í•˜ë‹¤. ì‹¤ì œ ì•”í™˜ìì— ëŒ€í•´ì„œ ì•„ë‹ˆë¼ê³  í•˜ëŠ” ê²ƒì´ ë” ìœ„í—˜í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

ê·¸ë ‡ë‹¤ë©´ ë¹„ë¡ Interpretableí•˜ë”ë¼ë„ Attentionì€ ê³¼ì—° ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€? ì¦‰, ì˜ ì•„ëŠ” ê²ƒì— ëŒ€í•´ì„  ì˜ ì•ˆë‹¤ê³  (low variance), ì˜ ëª¨ë¥´ëŠ” ê²ƒì— ëŒ€í•´ì„œ ì˜ˆì¸¡ì„ ë©ˆì¶œ ìˆ˜ ìˆëŠ”ê°€? (I don't know)

ê¸°ì¡´ Attentionì€ í™•ì •ì  ëª¨ë¸ì´ë‹¤. ì¦‰, uncertaintyë¥¼ êµ¬í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ìœ„ ë¬¼ìŒì— ëŒ€í•´ ë‹µí•  ìˆ˜ ì—†ë‹¤.

ìœ„ì— ëŒ€í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì ìœ„ ë…¼ë¬¸ì˜ ì €ìëŠ” Uncertainty-Aware Attentionì„ ë„ì…í•˜ê²Œ ë˜ì—ˆê³ , ì ‘ê·¼í•œ ë°©ë²•ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

1. **Introducing stochastic attention mechanism**
    - stochastic approachë¥¼ í†µí•´ uncertaintyë¥¼ êµ¬í•œë‹¤.
2. **Input-dependent attention weights**
    - 1ì„ í™•ì¥í•˜ì—¬ Input-dependentí•œ Gaussian Distributionì„ ë”°ë¥´ëŠ” attention weightsë¥¼ êµ¬í•¨ìœ¼ë¡œì¨ instanceì— ë”°ë¥¸ uncertaintyë¥¼ êµ¬í•  ìˆ˜ ìˆê²Œ í•œë‹¤.

## 1. **Introducing** stochastic attention mechanism

![../assets/UAA/Untitled.png](../assets/UAA/Untitled.png)

ì—¬ê¸°ì„œ ajëŠ” ë² ë¥´ëˆ„ì´ ë¶„í¬ì„ ë”°ë¥´ê²Œ ë˜ëŠ”ë°, ìœ„ì— í•™ìŠµí•  ë• the evidence lower bound (ELBO)ë¥¼ maximizeí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ êµ¬í•˜ê²Œ ëœë‹¤.

ê·¸ëŸ¬ë‚˜ ìœ„ ë¶„í¬ë¥¼ í†µí•´ì„œ generatingí•˜ëŠ” attention-valueëŠ” standard deviationê°€ 0.5ë³´ë‹¤ í´ ìˆ˜ê°€ ì—†ìœ¼ë©°,

Instanceì— ë”°ë¥¸ uncertaintyë¥¼ êµ¬í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œì ì„ ê°–ê²Œ ëœë‹¤.

### 2. **Input-dependent attention weights**

![../assets/UAA/Untitled%201.png](../assets/UAA/Untitled%201.png)

ìœ„ì˜ ë¬¸ì œì ë“¤ì„ í•´ê²°í•˜ê³ ì ë¨¼ì € attention-strengthì™€ uncertatintyë¥¼ ë¶„ë¦¬ì˜€ëŠ”ë°,

sqaushingí•˜ê¸° ì „ attention-score(z)ë¥¼ generateí•  ë•Œ Input-dependent**(X í…€ì´ ê³ ë ¤ëœ)**í•œ ì¡°ê±´ë¶€ í™•ë¥ ì„ í†µí•´ì„œ scoreë¥¼ ìƒì„±í•œë‹¤. 

score-strengthëŠ” **Âµ,** uncertainty**ëŠ” ğ›”**ë¥¼ ë”°ë¼ê°€ëŠ” Input-dependentí•œ ì¡°ê±´ë¶€ í™•ë¥ ì˜ Gaussian Distributionìœ¼ë¡œ ìƒì„±í•œë‹¤.

ê²°ë¡ ì ìœ¼ë¡œ, model parameter ìì²´ë¥¼ random-variableë¡œ ì·¨ê¸‰í•˜ì§€ë§Œ ìœ„ë¥¼ í†µí•´ì„œ ìƒì„±ë˜ëŠ” attention-scoreëŠ” ê°ê¸° ë‹¤ë¥¸ Instance(**xì— ë”°ë¼**)ì— ëŒ€í•´ uncertaintyë¥¼ êµ¬í•  ìˆ˜ ìˆê²Œ ëœë‹¤.

ê·¸ëŸ¬ë‚˜, ìš°ë¦¬ê°€ ê´€ì‹¬ìˆëŠ” p(Z, Ï‰|D)ì˜ ê²½ìš° Marginal Probability(**P(D)**)ì— ëŒ€í•˜ì—¬ featuresë“¤ë¼ë¦¬ì˜ ë³µì¡í•œ êµ¬ì¡°ë¥¼ ë„ê³  ìˆëŠ” ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì´ê¸°ì— ê³„ì‚°ìì²´ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ìœ„í•´ Approximation ë°©ë²•ìœ¼ë¡œ Variational Inferenceë¥¼ ì´ìš©í•œë‹¤.

Monte-Carlo Samplingì„ í†µí•´ì„œ expectationì„ ê·¼ì‚¬í•˜ê³ , KL termì— ëŒ€í•´ì„œ dropout approxiamationê³¼ ê·¼ì‚¬ë¶„í¬ì™€ ì‹¤ì œë¶„í¬ì— ëŒ€í•œ ë™ì¼ì„±ì˜ ê°€ì •ì„ ì´ìš©í•˜ë©´ ìµœì¢…ì ìœ¼ë¡œ 

![../assets/UAA/Untitled%202.png](../assets/UAA/Untitled%202.png)

ìœ„ì™€ ê°™ì€ objectiveë¥¼ ê°–ê²Œ ëœë‹¤.

ìœ„ë¥¼ í†µí•´ í•™ìŠµí•œ ì´í›„ ì˜ˆì¸¡í•˜ëŠ” ë‹¨ê³„ì—ì„œë„ dropoutì— ë”°ë¥¸ parameterë¥¼ samplingí•œ í›„ Monte-Carlo Samplingì„ í†µí•´ ì˜ˆì¸¡í•˜ê²Œ ëœë‹¤. ì¦‰, ì˜ˆì¸¡í•˜ëŠ” ì‹œì ì—ì„œë„ dropoutí•˜ëŠ” parameterì— ë”°ë¥¸ samplingì˜ ê²°ê³¼ì— ë”°ë¼ attention score(z)ê°€ ë‚˜ì˜¤ê²Œ ëœë‹¤.

# ê·¸ëŸ¬ë©´ Uncertaintyì— ëŒ€í•´ì„œ í‰ê°€ë¥¼ ì–´ë–»ê²Œ í•  ìˆ˜ ìˆì„ê¹Œ?

![../assets/UAA/Untitled%203.png](../assets/UAA/Untitled%203.png)

ìœ„ ë…¼ë¬¸ì—ì„œëŠ” Expectation Calibration Errorë¼ëŠ” confidenceì™€ confidenceì— ë”°ë¥¸ ì •í™•ì„±ì— ëŒ€í•œ ì°¨ì´ë¥¼ ì ˆëŒ€ê°’ìœ¼ë¡œí•œ ê°’ì„ í‰ê· ìœ¼ë¡œ í•˜ì—¬ ê¸°ì¤€ì„ êµ¬í•œë‹¤.

![../assets/UAA/Untitled%204.png](../assets/UAA/Untitled%204.png)

ê·¸ ê²°ê³¼ë¡œ baselineì´ ë˜ëŠ” RETAIN-í™•ì •/í™•ë¥  ëª¨ë¸ê³¼ í•¨ê»˜ Input-dependentì˜ ì—¬ë¶€ì— ë”°ë¼ ê²°ê³¼ë¥¼ ë³´ì˜€ë‹¤.

UA(UA+)ê°€ ëª¨ë‘ baseline ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ê³ , Input-dependentí•œ ëª¨ë¸ë§ì´ ì˜í–¥ì´ ìˆë‹¤ë¼ëŠ” ê²ƒì„ ë³´ì—¬ì¤¬ë‹¤.

![../assets/UAA/Untitled%205.png](../assets/UAA/Untitled%205.png)

ë³¸ì§ˆì ìœ¼ë¡œ ìœ„ ëª¨ë¸ì„ í†µí•´ì„œ í™•ì¸í•˜ê³ ì í–ˆë˜ 

ì˜ ì•„ëŠ” ê²ƒì— ëŒ€í•´ì„  ì˜ ì•ˆë‹¤ê³  (low variance), ì˜ ëª¨ë¥´ëŠ” ê²ƒì— ëŒ€í•´ì„œ high varianceë¥¼ ê°–ëŠ” ì§€ë¥¼ featureë³„ë¡œ êµ¬í•˜ì˜€ë‹¤. 

ì‹¤ì œ previous timestampê°€ ì—†ëŠ” urineì´ë‚˜ normal rangeì—ì„œ ë²—ì–´ë‚˜ëŠ” Heart Rateì— ëŒ€í•´ì„œëŠ” **ë†’ì€ ë¶„ì‚°**ì„ ê°€ì§„ ë°˜ë©´, normal rangeë‚´ì—ì„œ cyclic changeê°€ ìˆëŠ” SysABPë‚˜ DiasABPì— ëŒ€í•´ì„  **ë‚®ì€ ë¶„ì‚°**ì„ ê°€ì§„ë‹¤.

![../assets/UAA/Untitled%206.png](../assets/UAA/Untitled%206.png)

ì˜ˆì¸¡ ê²°ê³¼ì—ì„œë„ í‹€ë¦¬ëŠ” ê²ƒë³´ë‹¤ I don't knowë¡œ ì˜ˆì¸¡í•˜ëŠ” ë¹„ìœ¨ì´ UA(UA+)ì´ baseline ëª¨ë¸ë³´ë‹¤ ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# ì˜ë¬¸ì 

1. ë§Œì•½ stochastic approachë¥¼ í•˜ëŠ” ê²Œ ì˜ë¯¸ê°€ ìˆë‹¤ë©´ baseline ëª¨ë¸ì¸ RETAIN ëª¨ë¸ì—ì„œë„ ê°™ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì•¼ í•  ê²ƒ ê°™ì€ë°, ë‘ ëª¨ë¸ì—ì„œ ì™œ ë‹¤ë¥¸ ê²°ê³¼ê°€ ìˆëŠ”ì§€?
    - multinoulli distributionìœ¼ë¡œ ëª¨ë¸ë§í•˜ì˜€ëŠ”ë°, distributionì— ë”°ë¼ ì„±ëŠ¥ì´ ì°¨ì´ê°€ ë‚œë‹¤ë©´ ë°ì´í„°ì— ë”°ë¼ ëª¨ë¸ë§ì„ ë‹¤ë¥´ê²Œ í•´ì•¼ í•˜ëŠ”ê±´ì§€?
2. ì‹¤ì œ healthcareì—ì„  Recallì´ ì¤‘ìš”í•œ metricì¸ë°, False Negative (Type 2 Error)ê°€ ë†’ê²Œ ë‚˜ì˜¤ëŠ” ê²Œ ë” ì¢‹ì€ ëª¨ë¸ì´ë¼ê³  í•  ìˆ˜ ìˆì„ì§€?

![../assets/UAA/Untitled%207.png](../assets/UAA/Untitled%207.png)
