---
layout: post
title:  "Cross Validation but, data leakage"
date:   2019-07-11
excerpt: "Cross Validation but, data leakage"
tag:
- python
- machine learning
- sklearn
comments: false
---

# Cross Validation

CV는 모두가 알고있는 기법이니 생략한다.

[개념](https://nonmeyet.tistory.com/entry/KFold-Cross-Validation교차검증-정의-및-설명)

[sklearn_option](https://woolulu.tistory.com/70)


## data leakage

모델링을 할 때 분석의 흐름이 데이터를 전처리한 후 scale한 데이터에 대해 cross-validation을 적용한다고 해보자.

``` python

df = ...

cleaned_df = preprocessing(df)

scaled_df = scaling(df)

from sklearn.model_selection import GridSearchCV

pipeline = ...


clf = GridSearchCV(**parameters,cv=5)

clf.fit(scaled_df,y)

```

데이터셋을 나누고, CV 과정에서 validation 데이터를 만든 후 모델링을 하고, 최적화된 파라미터를 찾을 것이다.

> 위와 같이 데이터 분석을 할 때 문제점이 무엇일까?
>
> data leakage 문제가 발생한다.

cross-validation을 하는 과정에서 scaled data, 예를 들어 normalize와 같은 연산을 한다고 했을 때 당연히 위의 코드에선 **scaling**이라는 함수를 통해서 전체 scaled_df에 적용될 것이다.

그러면 GridSearchCV에서 fold를 나누어지는  train/validation 데이터의 경우

validation이 어느 정도 train의 데이터에 대한 정보가 포함되어 있다는 의미다.

이러한 문제를 **data leakage**라고 말한다. 현업에서도 흔히 하는 실수다.

> 그러면, 이를 해결하기 위한 방법은?

정말 간단하다. validation 데이터를 scaling 혹은 *파생변수 만들기* 이전에 나누면 되는 것이다.

*파생변수가 variable들과의 단순 조합인 경우는 상관없으나, Min, Max 등 trainSet의 집합 내에서 이루어지게 되면 영향이 끼칠 것은 normalize하는 것과 같은 이치다.*

그러나, scikit-learn에서 더 좋은 방법이 있는데, 바로 우리가 알고있는 pipeline으로 만드는 것이다.

[piepline](https://ramhiser.com/post/2018-04-16-building-scikit-learn-pipeline-with-pandas-dataframe/)

> pipeline? 왠 갑자기 ?
> 
> GridSearchCV에서 cv=5 옵션을 넣었을 떄 나누어지는 데이터셋의 기준은 pipeline을 > 통하는 데이터 / 아닌 데이터다.
> 
> 그러면, pipeline에 scaler를 넣는다면?? 당연히 validationSet에 영향을 끼치지 않는다.

참고 사이트

[data-leakage](https://machinelearningmastery.com/data-leakage-machine-learning/)